{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1W5yAtlFvm6JgvpukZBWTeLmL9dZOpsyp","authorship_tag":"ABX9TyPV4ixdk1VYLCcR5wnBamzD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install scapy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6k50xju1pAH","executionInfo":{"status":"ok","timestamp":1762074741569,"user_tz":-420,"elapsed":5814,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"2bb9b436-9a83-4962-86ce-535cd8c5b9c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scapy\n","  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n","Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scapy\n","Successfully installed scapy-2.6.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Jr48or8P1DMe","executionInfo":{"status":"ok","timestamp":1762075362247,"user_tz":-420,"elapsed":593598,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"91310dbb-b819-41da-dfdf-980960452416"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing Alpha (α) v2 Component Script ---\n","All libraries imported successfully.\n","\n","--- PART 1: Extracting Packet Sequences ---\n","Reading from: /content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\n","Using N_PACKETS = 128 and LATENT_DIM = 32\n","Found 10284 .pcap files in the directory.\n","Processing files in parallel... (This may take several minutes)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.9s\n","[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    6.8s\n","[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=-1)]: Done 1085 tasks      | elapsed:  2.0min\n","[Parallel(n_jobs=-1)]: Done 1628 tasks      | elapsed:  2.5min\n","[Parallel(n_jobs=-1)]: Done 3040 tasks      | elapsed:  2.9min\n","/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","[Parallel(n_jobs=-1)]: Done 3708 tasks      | elapsed:  4.0min\n","[Parallel(n_jobs=-1)]: Done 5404 tasks      | elapsed:  4.5min\n","[Parallel(n_jobs=-1)]: Done 7541 tasks      | elapsed:  5.1min\n","[Parallel(n_jobs=-1)]: Done 9786 tasks      | elapsed:  5.5min\n","[Parallel(n_jobs=-1)]: Done 10284 out of 10284 | elapsed:  8.2min finished\n"]},{"output_type":"stream","name":"stdout","text":["File processing finished in 489.18 seconds.\n","Successfully processed 10105 files.\n","Skipped 179 empty/corrupted/unlabeled files.\n","\n","--- PART 2: Preparing Data for Autoencoder ---\n","Data shape for autoencoder: (10105, 128, 1)\n","Training data shape: (8084, 128, 1)\n","Validation data shape: (2021, 128, 1)\n","\n","--- PART 3: Building & Training Autoencoder ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m16,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m24,832\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m65\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,209\u001b[0m (211.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,209</span> (211.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,209\u001b[0m (211.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,209</span> (211.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training autoencoder...\n","Epoch 1/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 206ms/step - loss: nan - val_loss: nan\n","Epoch 2/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: nan - val_loss: nan\n","Epoch 3/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: nan - val_loss: nan\n","Epoch 4/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: nan - val_loss: nan\n","Epoch 5/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: nan - val_loss: nan\n","Epoch 6/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: nan - val_loss: nan\n","Autoencoder training complete.\n","\n","--- PART 4: Generating Alpha (α) Features ---\n","Generating 32-dimensional features for all 10105 samples...\n","\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n","Generated alpha features with shape: (10105, 32)\n","\n","--- PART 5: Saving Final Dataset ---\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Successfully saved final alpha component (v2) to:\n","/content/drive/MyDrive/1 Skripsi/alpha_component_v2.csv\n","Successfully saved encoder model to:\n","/content/drive/MyDrive/1 Skripsi/alpha_encoder_v2.h5\n","\n","--- Alpha (α) v2 Script Finished ---\n"]}],"source":["# --- Alpha (α) Component Extraction Script ---\n","# This script reads the 10,284 filtered .pcap files, extracts the\n","# first 128 packet sizes (with direction), and then trains an\n","# LSTM autoencoder to generate the 32-dimensional alpha (α) features.\n","\n","print(\"--- Initializing Alpha (α) v2 Component Script ---\")\n","\n","# --- Step 0: Install necessary libraries ---\n","# Scapy is required for reading .pcap files\n","try:\n","    import scapy.all as scapy\n","except ImportError:\n","    print(\"Installing scapy...\")\n","    # Use 'pip install' in a Colab cell, not subprocess\n","    # For this script, we'll assume it's run after !pip install scapy\n","    print(\"Please run '!pip install scapy' in a Colab cell and restart the runtime.\")\n","    # In a notebook, run: !pip install scapy\n","\n","import os\n","import collections\n","import time\n","import numpy as np\n","import pandas as pd\n","from joblib import Parallel, delayed\n","from scapy.all import rdpcap, IP\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# TensorFlow and Keras for the autoencoder\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","print(\"All libraries imported successfully.\")\n","\n","# --- PART 1: Configuration & Labeling Map ---\n","\n","# --- File & Path Configuration ---\n","# Directory containing the 10,284 .pcap files\n","FLOW_DIR = \"/content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\"\n","# Output CSV file\n","OUTPUT_CSV = \"/content/drive/MyDrive/1 Skripsi/alpha_component_v2.csv\"\n","# We'll also save the trained encoder model\n","ENCODER_MODEL_SAVE_PATH = \"/content/drive/MyDrive/1 Skripsi/alpha_encoder_v2.h5\"\n","\n","\n","# --- Feature Extraction Configuration ---\n","N_PACKETS = 128     # First N packets to use\n","MAX_PACKET_SIZE = 1500.0 # For normalization (maps to -1.0 to 1.0)\n","\n","# --- Autoencoder Configuration ---\n","LATENT_DIM = 32     # Dimensions of the final alpha vector (α)\n","EPOCHS = 50\n","BATCH_SIZE = 64\n","VALIDATION_SPLIT = 0.2\n","\n","# --- Labeling Map (Copied from your script) ---\n","KEYWORD_MAP = collections.OrderedDict([\n","    ('facebook_chat', ('Facebook', 'Chat')),\n","    ('facebookchat', ('Facebook', 'Chat')),\n","    ('hangouts_chat', ('Hangout', 'Chat')),\n","    ('hangout_chat', ('Hangout', 'Chat')),\n","    ('gmailchat', ('Gmail', 'Chat')),\n","    ('icq_chat', ('ICQ', 'Chat')),\n","    ('icqchat', ('ICQ', 'Chat')),\n","    ('skype_chat', ('Skype', 'Chat')),\n","    ('aim_chat', ('AIM Chat', 'Chat')),\n","    ('aimchat', ('AIM Chat', 'Chat')),\n","\n","    ('facebook_audio', ('Facebook', 'VoIP')),\n","    ('hangouts_audio', ('Hangout', 'VoIP')),\n","    ('skype_audio', ('Skype', 'VoIP')),\n","    ('voipbuster', ('VOIPBuster', 'VoIP')),\n","    ('facebook_video', ('Facebook', 'VoIP')),\n","    ('hangouts_video', ('Hangout', 'VoIP')),\n","    ('skype_video', ('Skype', 'VoIP')),\n","\n","    ('skype_file', ('Skype', 'File Transfer')),\n","    ('ftps', ('FTP', 'File Transfer')),\n","    ('sftp', ('SFTP', 'File Transfer')),\n","    ('scp', ('SCP', 'File Transfer')),\n","    ('ftp', ('FTP', 'File Transfer')),\n","\n","    ('email', ('Email', 'Email')),\n","    ('gmail', ('Gmail', 'Email')),\n","\n","    ('netflix', ('Netflix', 'Streaming')),\n","    ('spotify', ('Spotify', 'Streaming')),\n","    ('vimeo', ('Vimeo', 'Streaming')),\n","    ('youtube', ('YouTube', 'Streaming')),\n","\n","    ('bittorrent', ('BitTorrent', 'P2P')),\n","])\n","\n","# --- List of the 6 applications we are using ---\n","# This is used to sanity-check the labeling\n","TARGET_APPS = {\n","    'Skype', 'Email', 'SCP', 'VOIPBuster', 'YouTube', 'BitTorrent'\n","}\n","\n","\n","def get_flow_labels(filename):\n","    \"\"\"\n","    Parses a filename to get its labels (application, category, binary_type).\n","    \"\"\"\n","    lower_filename = filename.lower()\n","\n","    # 1. Determine Binary Type\n","    binary_type = 'VPN' if lower_filename.startswith('vpn_') else 'NonVPN'\n","\n","    # 2. Determine Application and Category\n","    for keyword, (application, category) in KEYWORD_MAP.items():\n","        if keyword in lower_filename:\n","            # Sanity check if the app is one we expect\n","            if application not in TARGET_APPS:\n","                # This should not happen if the filtering script was correct\n","                print(f\"Warning: Found app '{application}' not in TARGET_APPS.\")\n","\n","            return application, category, binary_type\n","\n","    # Fallback in case no keyword matches (e.g., FTP files named just 'ftp_...pcap')\n","    # This logic is based on our 6 target apps\n","    if 'scp' in lower_filename:\n","        return 'SCP', 'File Transfer', binary_type\n","    if 'email' in lower_filename:\n","        return 'Email', 'Email', binary_type\n","    if 'youtube' in lower_filename:\n","        return 'YouTube', 'Streaming', binary_type\n","    if 'bittorrent' in lower_filename:\n","        return 'BitTorrent', 'P2P', binary_type\n","\n","    # If we get here, it's an unclassified file\n","    return None, None, None\n","\n","def process_pcap_file(filename, base_dir):\n","    \"\"\"\n","    Reads a single .pcap file and extracts its packet sequence and labels.\n","    This function is designed to be run in parallel.\n","    \"\"\"\n","    filepath = os.path.join(base_dir, filename)\n","\n","    # 1. Get labels\n","    application, category, binary_type = get_flow_labels(filename)\n","    if application is None:\n","        print(f\"Skipping file (label not found): {filename}\")\n","        return None\n","\n","    # 2. Initialize packet sequence\n","    # We use a list and then convert to numpy array\n","    packet_sequence = []\n","\n","    try:\n","        packets = rdpcap(filepath)\n","\n","        # Find the client IP (source IP of the first IP packet)\n","        client_ip = None\n","        for pkt in packets:\n","            if IP in pkt:\n","                client_ip = pkt[IP].src\n","                break\n","\n","        if client_ip is None:\n","            # print(f\"Skipping file (no IP packets found): {filename}\")\n","            return None # Skip non-IP flows\n","\n","        # 3. Extract packet sizes with direction\n","        for pkt in packets:\n","            if IP in pkt:\n","                packet_size = pkt[IP].len\n","\n","                # Client-to-Server = positive\n","                if pkt[IP].src == client_ip:\n","                    packet_sequence.append(packet_size)\n","                # Server-to-Client = negative\n","                elif pkt[IP].dst == client_ip:\n","                    packet_sequence.append(-packet_size)\n","\n","            if len(packet_sequence) >= N_PACKETS:\n","                break # We only want the first N packets\n","\n","    except Exception as e:\n","        # This catches corrupted or unreadable files\n","        # print(f\"Skipping file (error reading pcap): {filename}, Error: {e}\")\n","        return None\n","\n","    if len(packet_sequence) == 0:\n","        # print(f\"Skipping file (empty sequence): {filename}\")\n","        return None\n","\n","    # 4. Pad or Truncate the sequence\n","    final_sequence = np.zeros(N_PACKETS)\n","    if len(packet_sequence) >= N_PACKETS:\n","        final_sequence = np.array(packet_sequence[:N_PACKETS])\n","    else:\n","        final_sequence[:len(packet_sequence)] = np.array(packet_sequence)\n","\n","    # 5. Normalize the sequence\n","    # Divide by 1500 to scale data between -1.0 and 1.0\n","    # This keeps 0.0 as 0.0 (padding)\n","    normalized_sequence = final_sequence / MAX_PACKET_SIZE\n","\n","    # Return all data as a dictionary\n","    return {\n","        'filename': filename,\n","        'application': application,\n","        'category': category,\n","        'binary_type': binary_type,\n","        'sequence': normalized_sequence\n","    }\n","\n","def build_autoencoder(n_packets, latent_dim):\n","    \"\"\"\n","    Builds the LSTM Autoencoder model.\n","    \"\"\"\n","    # Input shape is (timesteps, features) -> (128, 1)\n","    input_shape = (n_packets, 1)\n","\n","    # --- Encoder ---\n","    inputs = Input(shape=input_shape)\n","    # Using 64 units as an intermediate layer\n","    x = LSTM(64, activation='relu', return_sequences=True)(inputs)\n","    # The 'encoder_output' layer is our 32-dim latent vector\n","    encoder_output = LSTM(latent_dim, activation='relu', name='encoder_output')(x)\n","\n","    # --- Decoder ---\n","    # Repeat the latent vector for each timestep\n","    x = RepeatVector(n_packets)(encoder_output)\n","    x = LSTM(64, activation='relu', return_sequences=True)(x)\n","    # Reconstruct the original (128, 1) shape\n","    decoder_output = TimeDistributed(Dense(1))(x)\n","\n","    # --- Autoencoder Model ---\n","    autoencoder = Model(inputs=inputs, outputs=decoder_output)\n","    autoencoder.compile(optimizer='adam', loss='mse')\n","\n","    # --- Encoder-Only Model ---\n","    # This is the model we'll use to generate features\n","    encoder = Model(inputs=inputs, outputs=encoder_output)\n","\n","    return autoencoder, encoder\n","\n","# --- PART 2: Main Execution ---\n","def main():\n","    print(f\"\\n--- PART 1: Extracting Packet Sequences ---\")\n","    print(f\"Reading from: {FLOW_DIR}\")\n","    print(f\"Using N_PACKETS = {N_PACKETS} and LATENT_DIM = {LATENT_DIM}\")\n","\n","    if not os.path.isdir(FLOW_DIR):\n","        print(f\"FATAL: Source directory not found. Please check the path.\")\n","        return\n","\n","    filenames = os.listdir(FLOW_DIR)\n","    # Filter out non-pcap files just in case\n","    pcap_files = [f for f in filenames if f.endswith('.pcap') or f.endswith('.pcapng')]\n","    print(f\"Found {len(pcap_files)} .pcap files in the directory.\")\n","\n","    start_time = time.time()\n","\n","    # Use joblib to process files in parallel\n","    # n_jobs=-1 uses all available CPU cores\n","    print(\"Processing files in parallel... (This may take several minutes)\")\n","    results = Parallel(n_jobs=-1, verbose=5)(\n","        delayed(process_pcap_file)(f, FLOW_DIR) for f in pcap_files\n","    )\n","\n","    end_time = time.time()\n","    print(f\"File processing finished in {end_time - start_time:.2f} seconds.\")\n","\n","    # Filter out 'None' results from skipped/empty files\n","    valid_results = [r for r in results if r is not None]\n","\n","    if not valid_results:\n","        print(\"FATAL: No valid data was extracted. Stopping script.\")\n","        return\n","\n","    print(f\"Successfully processed {len(valid_results)} files.\")\n","    print(f\"Skipped {len(pcap_files) - len(valid_results)} empty/corrupted/unlabeled files.\")\n","\n","    # Create a DataFrame from the results\n","    df = pd.DataFrame(valid_results)\n","\n","    # --- PART 2: Preparing Data for Autoencoder ---\n","    print(\"\\n--- PART 2: Preparing Data for Autoencoder ---\")\n","\n","    # Extract the sequences and reshape for LSTM: (samples, timesteps, features)\n","    sequences = np.array(df['sequence'].tolist())\n","    # Reshape from (n_samples, 128) to (n_samples, 128, 1)\n","    X = sequences.reshape((sequences.shape[0], sequences.shape[1], 1))\n","\n","    print(f\"Data shape for autoencoder: {X.shape}\")\n","\n","    # Split into train/test for autoencoder training\n","    # We use the full dataset (X) to train the autoencoder\n","    X_train, X_test = train_test_split(X, test_size=VALIDATION_SPLIT, random_state=42)\n","\n","    print(f\"Training data shape: {X_train.shape}\")\n","    print(f\"Validation data shape: {X_test.shape}\")\n","\n","    # --- PART 3: Building & Training Autoencoder ---\n","    print(\"\\n--- PART 3: Building & Training Autoencoder ---\")\n","\n","    autoencoder, encoder = build_autoencoder(N_PACKETS, LATENT_DIM)\n","    autoencoder.summary()\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","    print(\"Training autoencoder...\")\n","    history = autoencoder.fit(\n","        X_train, X_train, # Autoencoder learns to reconstruct itself\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(X_test, X_test),\n","        callbacks=[early_stopping],\n","        verbose=1\n","    )\n","\n","    print(\"Autoencoder training complete.\")\n","\n","    # --- PART 4: Generating Alpha (α) Features ---\n","    print(\"\\n--- PART 4: Generating Alpha (α) Features ---\")\n","\n","    # Use the trained 'encoder' model to transform ALL sequences (not just X_train)\n","    # into the 32-dimensional latent space\n","    print(f\"Generating {LATENT_DIM}-dimensional features for all {X.shape[0]} samples...\")\n","    alpha_features = encoder.predict(X)\n","\n","    print(f\"Generated alpha features with shape: {alpha_features.shape}\")\n","\n","    # --- PART 5: Saving Final Dataset ---\n","    print(\"\\n--- PART 5: Saving Final Dataset ---\")\n","\n","    # Create column names for the alpha features\n","    alpha_cols = [f'alpha_{i}' for i in range(LATENT_DIM)]\n","\n","    # Create a new DataFrame for the features\n","    df_alpha = pd.DataFrame(alpha_features, columns=alpha_cols, index=df.index)\n","\n","    # Concatenate the original labels with the new alpha features\n","    df_final = pd.concat([\n","        df[['filename', 'application', 'category', 'binary_type']],\n","        df_alpha\n","    ], axis=1)\n","\n","    # Save the final CSV\n","    try:\n","        df_final.to_csv(OUTPUT_CSV, index=False)\n","        print(f\"Successfully saved final alpha component (v2) to:\")\n","        print(OUTPUT_CSV)\n","    except Exception as e:\n","        print(f\"Error saving final CSV: {e}\")\n","\n","    # Save the encoder model for later use (optional)\n","    try:\n","        encoder.save(ENCODER_MODEL_SAVE_PATH)\n","        print(f\"Successfully saved encoder model to:\")\n","        print(ENCODER_MODEL_SAVE_PATH)\n","    except Exception as e:\n","        print(f\"Error saving encoder model: {e}\")\n","\n","if __name__ == \"__main__\":\n","    # Ensure you have mounted your Google Drive\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","        print(\"from google.colab import drive; drive.mount('/content/drive')\")\n","    else:\n","        # Run the main process\n","        main()\n","\n","print(\"\\n--- Alpha (α) v2 Script Finished ---\")\n"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to the generated CSV file\n","OUTPUT_CSV = \"/content/drive/MyDrive/1 Skripsi/alpha_component_v2.csv\"\n","\n","# Read the CSV file into a pandas DataFrame\n","try:\n","    df_alpha_component = pd.read_csv(OUTPUT_CSV)\n","    # Display the head of the DataFrame\n","    display(df_alpha_component.head())\n","except FileNotFoundError:\n","    print(f\"Error: The file {OUTPUT_CSV} was not found.\")\n","except Exception as e:\n","    print(f\"An error occurred while reading the CSV file: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"F95UAIro1zOv","executionInfo":{"status":"ok","timestamp":1762075629889,"user_tz":-420,"elapsed":62,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"18162147-3325-46fc-ecd2-5f83f8f1b1bf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            filename application  \\\n","0  vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...       Skype   \n","1  vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...       Skype   \n","2  vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...       Skype   \n","3  vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...       Skype   \n","4  vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...       Skype   \n","\n","        category binary_type  alpha_0  alpha_1  alpha_2  alpha_3  alpha_4  \\\n","0  File Transfer         VPN      NaN      NaN      NaN      NaN      NaN   \n","1  File Transfer         VPN      NaN      NaN      NaN      NaN      NaN   \n","2  File Transfer         VPN      NaN      NaN      NaN      NaN      NaN   \n","3  File Transfer         VPN      NaN      NaN      NaN      NaN      NaN   \n","4  File Transfer         VPN      NaN      NaN      NaN      NaN      NaN   \n","\n","   alpha_5  ...  alpha_22  alpha_23  alpha_24  alpha_25  alpha_26  alpha_27  \\\n","0      NaN  ...       NaN       NaN       NaN       NaN       NaN       NaN   \n","1      NaN  ...       NaN       NaN       NaN       NaN       NaN       NaN   \n","2      NaN  ...       NaN       NaN       NaN       NaN       NaN       NaN   \n","3      NaN  ...       NaN       NaN       NaN       NaN       NaN       NaN   \n","4      NaN  ...       NaN       NaN       NaN       NaN       NaN       NaN   \n","\n","   alpha_28  alpha_29  alpha_30  alpha_31  \n","0       NaN       NaN       NaN       NaN  \n","1       NaN       NaN       NaN       NaN  \n","2       NaN       NaN       NaN       NaN  \n","3       NaN       NaN       NaN       NaN  \n","4       NaN       NaN       NaN       NaN  \n","\n","[5 rows x 36 columns]"],"text/html":["\n","  <div id=\"df-fb6b15f7-7920-450f-807e-0319848d14e3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>application</th>\n","      <th>category</th>\n","      <th>binary_type</th>\n","      <th>alpha_0</th>\n","      <th>alpha_1</th>\n","      <th>alpha_2</th>\n","      <th>alpha_3</th>\n","      <th>alpha_4</th>\n","      <th>alpha_5</th>\n","      <th>...</th>\n","      <th>alpha_22</th>\n","      <th>alpha_23</th>\n","      <th>alpha_24</th>\n","      <th>alpha_25</th>\n","      <th>alpha_26</th>\n","      <th>alpha_27</th>\n","      <th>alpha_28</th>\n","      <th>alpha_29</th>\n","      <th>alpha_30</th>\n","      <th>alpha_31</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...</td>\n","      <td>Skype</td>\n","      <td>File Transfer</td>\n","      <td>VPN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...</td>\n","      <td>Skype</td>\n","      <td>File Transfer</td>\n","      <td>VPN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...</td>\n","      <td>Skype</td>\n","      <td>File Transfer</td>\n","      <td>VPN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...</td>\n","      <td>Skype</td>\n","      <td>File Transfer</td>\n","      <td>VPN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vpn_skype_files1b.pcap.UDP_10-8-8-130_49539_21...</td>\n","      <td>Skype</td>\n","      <td>File Transfer</td>\n","      <td>VPN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 36 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb6b15f7-7920-450f-807e-0319848d14e3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fb6b15f7-7920-450f-807e-0319848d14e3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fb6b15f7-7920-450f-807e-0319848d14e3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-8d446114-1678-4a9d-8682-9c71323659b4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d446114-1678-4a9d-8682-9c71323659b4')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-8d446114-1678-4a9d-8682-9c71323659b4 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}]},{"cell_type":"code","source":["# --- Alpha (α) Component Extraction Script ---\n","# This script reads the 10,284 filtered .pcap files, extracts the\n","# first 128 packet sizes (with direction), and then trains an\n","# LSTM autoencoder to generate the 32-dimensional alpha (α) features.\n","\n","# --- v2-FIXED ---\n","# 1. Added np.clip() to the data processing to prevent exploding gradients.\n","# 2. Changed LSTM activations from 'relu' to 'tanh' for better stability.\n","# ------------------\n","\n","print(\"--- Initializing Alpha (α) v2 Component Script (FIXED) ---\")\n","\n","# --- Step 0: Install necessary libraries ---\n","# Scapy is required for reading .pcap files\n","try:\n","    import scapy.all as scapy\n","except ImportError:\n","    print(\"Installing scapy...\")\n","    # Use 'pip install' in a Colab cell, not subprocess\n","    # For this script, we'll assume it's run after !pip install scapy\n","    print(\"Please run '!pip install scapy' in a Colab cell and restart the runtime.\")\n","    # In a notebook, run: !pip install scapy\n","\n","import os\n","import collections\n","import time\n","import numpy as np\n","import pandas as pd\n","from joblib import Parallel, delayed\n","from scapy.all import rdpcap, IP\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# TensorFlow and Keras for the autoencoder\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","print(\"All libraries imported successfully.\")\n","\n","# --- PART 1: Configuration & Labeling Map ---\n","\n","# --- File & Path Configuration ---\n","# Directory containing the 10,284 .pcap files\n","FLOW_DIR = \"/content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\"\n","# Output CSV file\n","OUTPUT_CSV = \"/content/drive/MyDrive/1 Skripsi/alpha_component_v2.csv\"\n","# We'll also save the trained encoder model\n","ENCODER_MODEL_SAVE_PATH = \"/content/drive/MyDrive/1 Skripsi/alpha_encoder_v2.h5\"\n","\n","\n","# --- Feature Extraction Configuration ---\n","N_PACKETS = 128     # First N packets to use\n","MAX_PACKET_SIZE = 1500.0 # For normalization (maps to -1.0 to 1.0)\n","\n","# --- Autoencoder Configuration ---\n","LATENT_DIM = 32     # Dimensions of the final alpha vector (α)\n","EPOCHS = 50\n","BATCH_SIZE = 64\n","VALIDATION_SPLIT = 0.2\n","\n","# --- Labeling Map (Copied from your script) ---\n","KEYWORD_MAP = collections.OrderedDict([\n","    ('facebook_chat', ('Facebook', 'Chat')),\n","    ('facebookchat', ('Facebook', 'Chat')),\n","    ('hangouts_chat', ('Hangout', 'Chat')),\n","    ('hangout_chat', ('Hangout', 'Chat')),\n","    ('gmailchat', ('Gmail', 'Chat')),\n","    ('icq_chat', ('ICQ', 'Chat')),\n","    ('icqchat', ('ICQ', 'Chat')),\n","    ('skype_chat', ('Skype', 'Chat')),\n","    ('aim_chat', ('AIM Chat', 'Chat')),\n","    ('aimchat', ('AIM Chat', 'Chat')),\n","\n","    ('facebook_audio', ('Facebook', 'VoIP')),\n","    ('hangouts_audio', ('Hangout', 'VoIP')),\n","    ('skype_audio', ('Skype', 'VoIP')),\n","    ('voipbuster', ('VOIPBuster', 'VoIP')),\n","    ('facebook_video', ('Facebook', 'VoIP')),\n","    ('hangouts_video', ('Hangout', 'VoIP')),\n","    ('skype_video', ('Skype', 'VoIP')),\n","\n","    ('skype_file', ('Skype', 'File Transfer')),\n","    ('ftps', ('FTP', 'File Transfer')),\n","    ('sftp', ('SFTP', 'File Transfer')),\n","    ('scp', ('SCP', 'File Transfer')),\n","    ('ftp', ('FTP', 'File Transfer')),\n","\n","    ('email', ('Email', 'Email')),\n","    ('gmail', ('Gmail', 'Email')),\n","\n","    ('netflix', ('Netflix', 'Streaming')),\n","    ('spotify', ('Spotify', 'Streaming')),\n","    ('vimeo', ('Vimeo', 'Streaming')),\n","    ('youtube', ('YouTube', 'Streaming')),\n","\n","    ('bittorrent', ('BitTorrent', 'P2P')),\n","])\n","\n","# --- List of the 6 applications we are using ---\n","# This is used to sanity-check the labeling\n","TARGET_APPS = {\n","    'Skype', 'Email', 'SCP', 'VOIPBuster', 'YouTube', 'BitTorrent'\n","}\n","\n","\n","def get_flow_labels(filename):\n","    \"\"\"\n","    Parses a filename to get its labels (application, category, binary_type).\n","    \"\"\"\n","    lower_filename = filename.lower()\n","\n","    # 1. Determine Binary Type\n","    binary_type = 'VPN' if lower_filename.startswith('vpn_') else 'NonVPN'\n","\n","    # 2. Determine Application and Category\n","    for keyword, (application, category) in KEYWORD_MAP.items():\n","        if keyword in lower_filename:\n","            # Sanity check if the app is one we expect\n","            if application not in TARGET_APPS:\n","                # This should not happen if the filtering script was correct\n","                # We can allow 'SCP' to not be in the keyword map\n","                if application == 'SCP':\n","                   return 'SCP', 'File Transfer', binary_type\n","\n","                print(f\"Warning: Found app '{application}' not in TARGET_APPS.\")\n","\n","            return application, category, binary_type\n","\n","    # Fallback in case no keyword matches (e.g., FTP files named just 'ftp_...pcap')\n","    # This logic is based on our 6 target apps\n","    if 'scp' in lower_filename:\n","        return 'SCP', 'File Transfer', binary_type\n","    if 'email' in lower_filename:\n","        return 'Email', 'Email', binary_type\n","    if 'youtube' in lower_filename:\n","        return 'YouTube', 'Streaming', binary_type\n","    if 'bittorrent' in lower_filename:\n","        return 'BitTorrent', 'P2P', binary_type\n","\n","    # If we get here, it's an unclassified file\n","    # Check for 'skype', 'voipbuster' which might not have hit keywords\n","    if 'skype' in lower_filename:\n","        return 'Skype', 'Unknown', binary_type # Fallback, should be caught by keywords\n","    if 'voipbuster' in lower_filename:\n","        return 'VOIPBuster', 'VoIP', binary_type\n","\n","    return None, None, None\n","\n","def process_pcap_file(filename, base_dir):\n","    \"\"\"\n","    Reads a single .pcap file and extracts its packet sequence and labels.\n","    This function is designed to be run in parallel.\n","    \"\"\"\n","    filepath = os.path.join(base_dir, filename)\n","\n","    # 1. Get labels\n","    application, category, binary_type = get_flow_labels(filename)\n","    if application is None:\n","        # print(f\"Skipping file (label not found): {filename}\")\n","        return None\n","\n","    # 2. Initialize packet sequence\n","    packet_sequence = []\n","\n","    try:\n","        packets = rdpcap(filepath)\n","\n","        client_ip = None\n","        for pkt in packets:\n","            if IP in pkt:\n","                client_ip = pkt[IP].src\n","                break\n","\n","        if client_ip is None:\n","            return None # Skip non-IP flows\n","\n","        # 3. Extract packet sizes with direction\n","        for pkt in packets:\n","            if IP in pkt:\n","                packet_size = pkt[IP].len\n","\n","                if pkt[IP].src == client_ip:\n","                    packet_sequence.append(packet_size)\n","                elif pkt[IP].dst == client_ip:\n","                    packet_sequence.append(-packet_size)\n","\n","            if len(packet_sequence) >= N_PACKETS:\n","                break\n","\n","    except Exception as e:\n","        return None\n","\n","    if len(packet_sequence) == 0:\n","        return None\n","\n","    # 4. Pad or Truncate the sequence\n","    final_sequence = np.zeros(N_PACKETS)\n","    if len(packet_sequence) >= N_PACKETS:\n","        final_sequence = np.array(packet_sequence[:N_PACKETS])\n","    else:\n","        final_sequence[:len(packet_sequence)] = np.array(packet_sequence)\n","\n","    # 5. Normalize the sequence\n","    normalized_sequence = final_sequence / MAX_PACKET_SIZE\n","\n","    # --- THIS IS THE FIX ---\n","    # Clip values to [-1.0, 1.0] to prevent extreme values from jumbo frames\n","    normalized_sequence = np.clip(normalized_sequence, -1.0, 1.0) # <-- FIX 1\n","    # --- END FIX ---\n","\n","    return {\n","        'filename': filename,\n","        'application': application,\n","        'category': category,\n","        'binary_type': binary_type,\n","        'sequence': normalized_sequence\n","    }\n","\n","def build_autoencoder(n_packets, latent_dim):\n","    \"\"\"\n","    Builds the LSTM Autoencoder model.\n","    \"\"\"\n","    input_shape = (n_packets, 1)\n","\n","    # --- Encoder ---\n","    inputs = Input(shape=input_shape)\n","    # Using 64 units as an intermediate layer\n","    # Changed activation to 'tanh' for stability\n","    x = LSTM(64, activation='tanh', return_sequences=True)(inputs) # <-- FIX 2\n","    # The 'encoder_output' layer is our 32-dim latent vector\n","    encoder_output = LSTM(latent_dim, activation='tanh', name='encoder_output')(x) # <-- FIX 3\n","\n","    # --- Decoder ---\n","    x = RepeatVector(n_packets)(encoder_output)\n","    x = LSTM(64, activation='tanh', return_sequences=True)(x) # <-- FIX 4\n","    decoder_output = TimeDistributed(Dense(1))(x)\n","\n","    autoencoder = Model(inputs=inputs, outputs=decoder_output)\n","    autoencoder.compile(optimizer='adam', loss='mse')\n","\n","    encoder = Model(inputs=inputs, outputs=encoder_output)\n","\n","    return autoencoder, encoder\n","\n","# --- PART 2: Main Execution ---\n","def main():\n","    print(f\"\\n--- PART 1: Extracting Packet Sequences ---\")\n","    print(f\"Reading from: {FLOW_DIR}\")\n","    print(f\"Using N_PACKETS = {N_PACKETS} and LATENT_DIM = {LATENT_DIM}\")\n","\n","    if not os.path.isdir(FLOW_DIR):\n","        print(f\"FATAL: Source directory not found. Please check the path.\")\n","        return\n","\n","    filenames = os.listdir(FLOW_DIR)\n","    pcap_files = [f for f in filenames if f.endswith('.pcap') or f.endswith('.pcapng')]\n","    print(f\"Found {len(pcap_files)} .pcap files in the directory.\")\n","\n","    start_time = time.time()\n","\n","    print(\"Processing files in parallel... (This may take several minutes)\")\n","    results = Parallel(n_jobs=-1, verbose=5)(\n","        delayed(process_pcap_file)(f, FLOW_DIR) for f in pcap_files\n","    )\n","\n","    end_time = time.time()\n","    print(f\"File processing finished in {end_time - start_time:.2f} seconds.\")\n","\n","    valid_results = [r for r in results if r is not None]\n","\n","    if not valid_results:\n","        print(\"FATAL: No valid data was extracted. Stopping script.\")\n","        return\n","\n","    print(f\"Successfully processed {len(valid_results)} files.\")\n","    print(f\"Skipped {len(pcap_files) - len(valid_results)} empty/corrupted/unlabeled files.\")\n","\n","    df = pd.DataFrame(valid_results)\n","\n","    # --- PART 2: Preparing Data for Autoencoder ---\n","    print(\"\\n--- PART 2: Preparing Data for Autoencoder ---\")\n","\n","    sequences = np.array(df['sequence'].tolist())\n","    X = sequences.reshape((sequences.shape[0], sequences.shape[1], 1))\n","\n","    # --- Check for NaNs *before* training ---\n","    if np.isnan(X).any():\n","        print(\"FATAL: 'NaN' values found in the processed sequences *before* training.\")\n","        print(\"This indicates a problem with the process_pcap_file function.\")\n","        return\n","    else:\n","        print(\"Data sanity check passed: No NaN values found in input data.\")\n","\n","    print(f\"Data shape for autoencoder: {X.shape}\")\n","\n","    X_train, X_test = train_test_split(X, test_size=VALIDATION_SPLIT, random_state=42)\n","\n","    print(f\"Training data shape: {X_train.shape}\")\n","    print(f\"Validation data shape: {X_test.shape}\")\n","\n","    # --- PART 3: Building & Training Autoencoder ---\n","    print(\"\\n--- PART 3: Building & Training Autoencoder ---\")\n","\n","    autoencoder, encoder = build_autoencoder(N_PACKETS, LATENT_DIM)\n","    autoencoder.summary()\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","    print(\"Training autoencoder...\")\n","    history = autoencoder.fit(\n","        X_train, X_train,\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(X_test, X_test),\n","        callbacks=[early_stopping],\n","        verbose=1\n","    )\n","\n","    print(\"Autoencoder training complete.\")\n","\n","    # --- PART 4: Generating Alpha (α) Features ---\n","    print(\"\\n--- PART 4: Generating Alpha (α) Features ---\")\n","\n","    print(f\"Generating {LATENT_DIM}-dimensional features for all {X.shape[0]} samples...\")\n","    alpha_features = encoder.predict(X)\n","\n","    print(f\"Generated alpha features with shape: {alpha_features.shape}\")\n","\n","    # --- Check for NaNs *after* training ---\n","    if np.isnan(alpha_features).any():\n","        print(\"ERROR: 'NaN' values found in the *output* features.\")\n","        print(\"This means the model training still failed. Check loss values above.\")\n","    else:\n","        print(\"Feature generation sanity check passed: No NaN values found in output.\")\n","\n","    # --- PART 5: Saving Final Dataset ---\n","    print(\"\\n--- PART 5: Saving Final Dataset ---\")\n","\n","    alpha_cols = [f'alpha_{i}' for i in range(LATENT_DIM)]\n","    df_alpha = pd.DataFrame(alpha_features, columns=alpha_cols, index=df.index)\n","\n","    df_final = pd.concat([\n","        df[['filename', 'application', 'category', 'binary_type']],\n","        df_alpha\n","    ], axis=1)\n","\n","    try:\n","        df_final.to_csv(OUTPUT_CSV, index=False)\n","        print(f\"Successfully saved final alpha component (v2) to:\")\n","        print(OUTPUT_CSV)\n","    except Exception as e:\n","        print(f\"Error saving final CSV: {e}\")\n","\n","    try:\n","        encoder.save(ENCODER_MODEL_SAVE_PATH)\n","        print(f\"Successfully saved encoder model to:\")\n","        print(ENCODER_MODEL_SAVE_PATH)\n","    except Exception as e:\n","        print(f\"Error saving encoder model: {e}\")\n","\n","if __name__ == \"__main__\":\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","        print(\"from google.colab import drive; drive.mount('/content/drive')\")\n","    else:\n","        main()\n","\n","print(\"\\n--- Alpha (α) v2 Script Finished (FIXED) ---\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tYHYw0Np5FfQ","executionInfo":{"status":"ok","timestamp":1762076431718,"user_tz":-420,"elapsed":513391,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"a3d11a18-f05d-4499-f534-57f56c5ac19a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing Alpha (α) v2 Component Script (FIXED) ---\n","All libraries imported successfully.\n","\n","--- PART 1: Extracting Packet Sequences ---\n","Reading from: /content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\n","Using N_PACKETS = 128 and LATENT_DIM = 32\n","Found 10284 .pcap files in the directory.\n","Processing files in parallel... (This may take several minutes)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n","[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.3s\n","[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=-1)]: Done 786 tasks      | elapsed:  1.3min\n","[Parallel(n_jobs=-1)]: Done 1021 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=-1)]: Done 1708 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=-1)]: Done 3252 tasks      | elapsed:  2.7min\n","/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","[Parallel(n_jobs=-1)]: Done 3772 tasks      | elapsed:  3.5min\n","[Parallel(n_jobs=-1)]: Done 5245 tasks      | elapsed:  3.9min\n","[Parallel(n_jobs=-1)]: Done 7590 tasks      | elapsed:  4.6min\n"]},{"output_type":"stream","name":"stdout","text":["File processing finished in 459.79 seconds.\n","Successfully processed 10105 files.\n","Skipped 179 empty/corrupted/unlabeled files.\n","\n","--- PART 2: Preparing Data for Autoencoder ---\n","Data sanity check passed: No NaN values found in input data.\n","Data shape for autoencoder: (10105, 128, 1)\n","Training data shape: (8084, 128, 1)\n","Validation data shape: (2021, 128, 1)\n","\n","--- PART 3: Building & Training Autoencoder ---\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Done 10284 out of 10284 | elapsed:  7.7min finished\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m16,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (\u001b[38;5;33mLSTM\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m24,832\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m65\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,209\u001b[0m (211.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,209</span> (211.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,209\u001b[0m (211.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,209</span> (211.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training autoencoder...\n","Epoch 1/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.0148 - val_loss: 0.0154\n","Epoch 2/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0136 - val_loss: 0.0146\n","Epoch 3/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0129 - val_loss: 0.0145\n","Epoch 4/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0129 - val_loss: 0.0143\n","Epoch 5/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0129 - val_loss: 0.0145\n","Epoch 6/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0130 - val_loss: 0.0165\n","Epoch 7/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0133 - val_loss: 0.0141\n","Epoch 8/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0128 - val_loss: 0.0150\n","Epoch 9/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0127 - val_loss: 0.0139\n","Epoch 10/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0121 - val_loss: 0.0140\n","Epoch 11/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0124 - val_loss: 0.0141\n","Epoch 12/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0126 - val_loss: 0.0141\n","Epoch 13/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0127 - val_loss: 0.0142\n","Epoch 14/50\n","\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0131 - val_loss: 0.0140\n","Autoencoder training complete.\n","\n","--- PART 4: Generating Alpha (α) Features ---\n","Generating 32-dimensional features for all 10105 samples...\n","\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","Generated alpha features with shape: (10105, 32)\n","Feature generation sanity check passed: No NaN values found in output.\n","\n","--- PART 5: Saving Final Dataset ---\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Successfully saved final alpha component (v2) to:\n","/content/drive/MyDrive/1 Skripsi/alpha_component_v2.csv\n","Successfully saved encoder model to:\n","/content/drive/MyDrive/1 Skripsi/alpha_encoder_v2.h5\n","\n","--- Alpha (α) v2 Script Finished (FIXED) ---\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Xn5WJ-AV6L6Z"},"execution_count":null,"outputs":[]}]}