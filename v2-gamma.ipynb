{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"13PtOQHJOr_-411pVA9zIJGJzeOhZNLD1","authorship_tag":"ABX9TyNbhB6/RL8nU8pCYDicj/At"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install scapy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK5yU1EbEO9l","executionInfo":{"status":"ok","timestamp":1762079292948,"user_tz":-420,"elapsed":7920,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"41ffd19f-9542-4fe7-ee0f-4566d2c7d17b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scapy\n","  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n","Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scapy\n","Successfully installed scapy-2.6.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4Qvi5yRECVH","executionInfo":{"status":"ok","timestamp":1762080179230,"user_tz":-420,"elapsed":886279,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"ceaad674-2da2-46d0-be51-a02cfd7a57a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing Gamma-Prime (γ') v2 Component Script ---\n","All libraries imported successfully.\n","\n","--- PART 1: Extracting Gamma-Prime (γ') Features ---\n","Reading from: /content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\n","Using Burst Idle Threshold: 1.0s\n","Found 10284 .pcap files in the directory.\n","Processing files in parallel... (This may take several minutes)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.7s\n","[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    7.6s\n","[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   15.3s\n","[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  4.6min\n","[Parallel(n_jobs=-1)]: Done 865 tasks      | elapsed:  4.9min\n","[Parallel(n_jobs=-1)]: Done 1278 tasks      | elapsed:  5.7min\n","[Parallel(n_jobs=-1)]: Done 2071 tasks      | elapsed:  5.8min\n","[Parallel(n_jobs=-1)]: Done 2992 tasks      | elapsed:  6.2min\n","/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","[Parallel(n_jobs=-1)]: Done 3637 tasks      | elapsed:  7.8min\n","[Parallel(n_jobs=-1)]: Done 4896 tasks      | elapsed:  8.1min\n","[Parallel(n_jobs=-1)]: Done 6447 tasks      | elapsed:  9.0min\n","[Parallel(n_jobs=-1)]: Done 7274 tasks      | elapsed:  9.6min\n","[Parallel(n_jobs=-1)]: Done 8814 tasks      | elapsed: 10.2min\n","[Parallel(n_jobs=-1)]: Done 10284 out of 10284 | elapsed: 14.0min finished\n"]},{"output_type":"stream","name":"stdout","text":["File processing finished in 840.66 seconds.\n","Successfully processed 10105 files.\n","Skipped 179 empty/corrupted/unlabeled files.\n","\n","--- PART 2: Saving Final Dataset ---\n","Successfully saved final gamma-prime component (v2) to:\n","/content/drive/MyDrive/1 Skripsi/gamma_prime_component_v2.csv\n","\n","--- Gamma-Prime (γ') v2 Script Finished ---\n"]}],"source":["# --- Gamma-Prime (γ') Component Extraction Script ---\n","# This script reads the 10,284 filtered .pcap files and generates\n","# the \"Gamma-Prime\" component: a detailed statistical profile of\n","# the flow's burst behavior.\n","# This component replaces the original Gamma (γ) component.\n","\n","print(\"--- Initializing Gamma-Prime (γ') v2 Component Script ---\")\n","\n","# --- Step 0: Ensure scapy is installed ---\n","try:\n","    import scapy.all as scapy\n","except ImportError:\n","    print(\"Please run '!pip install scapy' in a Colab cell and restart the runtime.\")\n","    # In a notebook, run: !pip install scapy\n","\n","import os\n","import collections\n","import time\n","import numpy as np\n","import pandas as pd\n","from joblib import Parallel, delayed\n","from scapy.all import rdpcap, IP\n","\n","print(\"All libraries imported successfully.\")\n","\n","# --- PART 1: Configuration & Labeling Map ---\n","\n","# --- File & Path Configuration ---\n","FLOW_DIR = \"/content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/v2-final_flows\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/1 Skripsi/gamma_prime_component_v2.csv\"\n","\n","# --- Burst Definition ---\n","# From your original documentation:\n","# A burst is a group of packets where the idle time between them is < 1.0s\n","BURST_IDLE_THRESHOLD = 1.0\n","\n","# --- Labeling Map (Copied from your script) ---\n","KEYWORD_MAP = collections.OrderedDict([\n","    ('facebook_chat', ('Facebook', 'Chat')),\n","    ('facebookchat', ('Facebook', 'Chat')),\n","    ('hangouts_chat', ('Hangout', 'Chat')),\n","    ('hangout_chat', ('Hangout', 'Chat')),\n","    ('gmailchat', ('Gmail', 'Chat')),\n","    ('icq_chat', ('ICQ', 'Chat')),\n","    ('icqchat', ('ICQ', 'Chat')),\n","    ('skype_chat', ('Skype', 'Chat')),\n","    ('aim_chat', ('AIM Chat', 'Chat')),\n","    ('aimchat', ('AIM Chat', 'Chat')),\n","\n","    ('facebook_audio', ('Facebook', 'VoIP')),\n","    ('hangouts_audio', ('Hangout', 'VoIP')),\n","    ('skype_audio', ('Skype', 'VoIP')),\n","    ('voipbuster', ('VOIPBuster', 'VoIP')),\n","    ('facebook_video', ('Facebook', 'VoIP')),\n","    ('hangouts_video', ('Hangout', 'VoIP')),\n","    ('skype_video', ('Skype', 'VoIP')),\n","\n","    ('skype_file', ('Skype', 'File Transfer')),\n","    ('ftps', ('FTP', 'File Transfer')),\n","    ('sftp', ('SFTP', 'File Transfer')),\n","    ('scp', ('SCP', 'File Transfer')),\n","    ('ftp', ('FTP', 'File Transfer')),\n","\n","    ('email', ('Email', 'Email')),\n","    ('gmail', ('Gmail', 'Email')),\n","\n","    ('netflix', ('Netflix', 'Streaming')),\n","    ('spotify', ('Spotify', 'Streaming')),\n","    ('vimeo', ('Vimeo', 'Streaming')),\n","    ('youtube', ('YouTube', 'Streaming')),\n","\n","    ('bittorrent', ('BitTorrent', 'P2P')),\n","])\n","\n","# --- List of the 6 applications we are using ---\n","TARGET_APPS = {\n","    'Skype', 'Email', 'SCP', 'VOIPBuster', 'YouTube', 'BitTorrent'\n","}\n","\n","\n","def get_flow_labels(filename):\n","    \"\"\"\n","    Parses a filename to get its labels (application, category, binary_type).\n","    \"\"\"\n","    lower_filename = filename.lower()\n","    binary_type = 'VPN' if lower_filename.startswith('vpn_') else 'NonVPN'\n","\n","    for keyword, (application, category) in KEYWORD_MAP.items():\n","        if keyword in lower_filename:\n","            if application not in TARGET_APPS:\n","                 # Allow 'SCP' to not be in the keyword map\n","                if application == 'SCP':\n","                   return 'SCP', 'File Transfer', binary_type\n","                print(f\"Warning: Found app '{application}' not in TARGET_APPS.\")\n","            return application, category, binary_type\n","\n","    # Fallback logic for our 6 target apps\n","    if 'scp' in lower_filename:\n","        return 'SCP', 'File Transfer', binary_type\n","    if 'email' in lower_filename:\n","        return 'Email', 'Email', binary_type\n","    if 'youtube' in lower_filename:\n","        return 'YouTube', 'Streaming', binary_type\n","    if 'bittorrent' in lower_filename:\n","        return 'BitTorrent', 'P2P', binary_type\n","    if 'skype' in lower_filename:\n","         # This is a fallback, 'skype_chat' etc. should catch first\n","        return 'Skype', 'Unknown', binary_type\n","    if 'voipbuster' in lower_filename:\n","        return 'VOIPBuster', 'VoIP', binary_type\n","\n","    return None, None, None\n","\n","def calculate_stats(data_list, prefix):\n","    \"\"\"\n","    Calculates a full statistical profile for a list of numbers.\n","    Returns a dictionary of features.\n","    \"\"\"\n","    stats = {}\n","\n","    stat_names = ['count', 'sum', 'mean', 'std', 'min', 'max', 'median', 'p25', 'p75']\n","    for name in stat_names:\n","        # We use prefix (e.g., 'burst_vol') to create feature names\n","        stats[f\"{prefix}_{name}\"] = 0.0\n","\n","    if not data_list:\n","        return stats\n","\n","    arr = np.array(data_list)\n","\n","    stats[f\"{prefix}_count\"] = float(arr.size)\n","    stats[f\"{prefix}_sum\"] = float(np.sum(arr))\n","    stats[f\"{prefix}_mean\"] = float(np.mean(arr))\n","    stats[f\"{prefix}_min\"] = float(np.min(arr))\n","    stats[f\"{prefix}_max\"] = float(np.max(arr))\n","    stats[f\"{prefix}_median\"] = float(np.median(arr))\n","    stats[f\"{prefix}_p25\"] = float(np.percentile(arr, 25))\n","    stats[f\"{prefix}_p75\"] = float(np.percentile(arr, 75))\n","\n","    if arr.size > 1:\n","        stats[f\"{prefix}_std\"] = float(np.std(arr))\n","\n","    return stats\n","\n","\n","def process_pcap_file(filename, base_dir):\n","    \"\"\"\n","    Reads a single .pcap file and extracts its full burst statistics.\n","    Designed to be run in parallel.\n","    \"\"\"\n","    filepath = os.path.join(base_dir, filename)\n","\n","    # 1. Get labels\n","    application, category, binary_type = get_flow_labels(filename)\n","    if application is None:\n","        return None\n","\n","    all_packets = [] # List to hold (time, size) tuples\n","\n","    try:\n","        packets = rdpcap(filepath)\n","\n","        client_ip = None\n","        for pkt in packets:\n","            if IP in pkt:\n","                client_ip = pkt[IP].src\n","                break\n","\n","        if client_ip is None:\n","            return None # Skip non-IP flows\n","\n","        # 3. Extract *all* IP packets from the flow (bidirectional)\n","        for pkt in packets:\n","            if IP in pkt:\n","                # Only include packets that are part of this flow\n","                if pkt[IP].src == client_ip or pkt[IP].dst == client_ip:\n","                    packet_size = float(pkt[IP].len)\n","                    packet_time = float(pkt.time)\n","                    all_packets.append((packet_time, packet_size))\n","\n","    except Exception as e:\n","        # Catches corrupted or unreadable files\n","        # print(f\"Skipping file (error reading pcap): {filename}, Error: {e}\")\n","        return None\n","\n","    if not all_packets:\n","        return None\n","\n","    # 4. Sort packets by time\n","    all_packets.sort(key=lambda x: x[0])\n","\n","    # 5. Calculate bursts\n","    burst_packet_counts = []\n","    burst_volumes = []\n","    burst_durations = []\n","    burst_idle_times = [] # Idle time *between* bursts\n","\n","    if not all_packets:\n","        # Handle empty (but valid) flow\n","        pass\n","\n","    # State for the first burst\n","    current_burst_packets = 1\n","    current_burst_volume = all_packets[0][1] # Size of first packet\n","    current_burst_start_time = all_packets[0][0] # Time of first packet\n","    last_packet_time = all_packets[0][0]\n","\n","    # Iterate from the *second* packet onwards\n","    for (pkt_time, pkt_size) in all_packets[1:]:\n","        idle_time = pkt_time - last_packet_time\n","\n","        if idle_time < BURST_IDLE_THRESHOLD:\n","            # --- This packet is PART of the current burst ---\n","            current_burst_packets += 1\n","            current_burst_volume += pkt_size\n","        else:\n","            # --- This packet is the START of a new burst ---\n","            # 1. Save the previous burst\n","            burst_duration = last_packet_time - current_burst_start_time\n","            burst_packet_counts.append(current_burst_packets)\n","            burst_volumes.append(current_burst_volume)\n","            burst_durations.append(burst_duration)\n","\n","            # 2. Save the idle time that just ended\n","            burst_idle_times.append(idle_time)\n","\n","            # 3. Reset for the new burst\n","            current_burst_packets = 1\n","            current_burst_volume = pkt_size\n","            current_burst_start_time = pkt_time\n","\n","        # Update the time of the last packet seen\n","        last_packet_time = pkt_time\n","\n","    # 6. Save the *final* burst after the loop\n","    # (This handles 1-packet flows as well)\n","    burst_duration = last_packet_time - current_burst_start_time\n","    burst_packet_counts.append(current_burst_packets)\n","    burst_volumes.append(current_burst_volume)\n","    burst_durations.append(burst_duration)\n","\n","    # 7. Calculate all statistical features\n","    features = {}\n","    features['total_burst_count'] = float(len(burst_packet_counts))\n","\n","    features.update(calculate_stats(burst_packet_counts, \"burst_pkt_count\"))\n","    features.update(calculate_stats(burst_volumes, \"burst_vol\"))\n","    features.update(calculate_stats(burst_durations, \"burst_dur\"))\n","    features.update(calculate_stats(burst_idle_times, \"burst_idle\"))\n","\n","    # 8. Add labels\n","    labels = {\n","        'filename': filename,\n","        'application': application,\n","        'category': category,\n","        'binary_type': binary_type\n","    }\n","\n","    # Combine labels and features\n","    labels.update(features)\n","    return labels\n","\n","# --- PART 2: Main Execution ---\n","def main():\n","    print(f\"\\n--- PART 1: Extracting Gamma-Prime (γ') Features ---\")\n","    print(f\"Reading from: {FLOW_DIR}\")\n","    print(f\"Using Burst Idle Threshold: {BURST_IDLE_THRESHOLD}s\")\n","\n","    if not os.path.isdir(FLOW_DIR):\n","        print(f\"FATAL: Source directory not found. Please check the path.\")\n","        return\n","\n","    filenames = os.listdir(FLOW_DIR)\n","    pcap_files = [f for f in filenames if f.endswith('.pcap') or f.endswith('.pcapng')]\n","    print(f\"Found {len(pcap_files)} .pcap files in the directory.\")\n","\n","    start_time = time.time()\n","\n","    print(\"Processing files in parallel... (This may take several minutes)\")\n","    results = Parallel(n_jobs=-1, verbose=5)(\n","        delayed(process_pcap_file)(f, FLOW_DIR) for f in pcap_files\n","    )\n","\n","    end_time = time.time()\n","    print(f\"File processing finished in {end_time - start_time:.2f} seconds.\")\n","\n","    valid_results = [r for r in results if r is not None]\n","\n","    if not valid_results:\n","        print(\"FATAL: No valid data was extracted. Stopping script.\")\n","        return\n","\n","    print(f\"Successfully processed {len(valid_results)} files.\")\n","    print(f\"Skipped {len(pcap_files) - len(valid_results)} empty/corrupted/unlabeled files.\")\n","\n","    df_final = pd.DataFrame(valid_results)\n","\n","    # --- PART 2: Saving Final Dataset ---\n","    print(\"\\n--- PART 2: Saving Final Dataset ---\")\n","\n","    try:\n","        df_final.to_csv(OUTPUT_CSV, index=False)\n","        print(f\"Successfully saved final gamma-prime component (v2) to:\")\n","        print(OUTPUT_CSV)\n","    except Exception as e:\n","        print(f\"Error saving final CSV: {e}\")\n","\n","if __name__ == \"__main__\":\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","        print(\"from google.colab import drive; drive.mount('/content/drive')\")\n","    else:\n","        main()\n","\n","print(\"\\n--- Gamma-Prime (γ') v2 Script Finished ---\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"gEhjF8NiEeI2"},"execution_count":null,"outputs":[]}]}